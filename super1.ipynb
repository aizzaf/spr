{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["LOADING DATA"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-02T15:32:58.702624Z","iopub.status.busy":"2023-02-02T15:32:58.702102Z","iopub.status.idle":"2023-02-02T15:33:03.967049Z","shell.execute_reply":"2023-02-02T15:33:03.965989Z","shell.execute_reply.started":"2023-02-02T15:32:58.702526Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-11 03:30:34.048524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-11 03:30:34.170138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2023-02-11 03:30:34.170161: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-02-11 03:30:35.146038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2023-02-11 03:30:35.146130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2023-02-11 03:30:35.146146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import multiprocessing\n","import functools"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-02T15:34:31.477668Z","iopub.status.busy":"2023-02-02T15:34:31.476878Z","iopub.status.idle":"2023-02-02T15:34:31.483427Z","shell.execute_reply":"2023-02-02T15:34:31.482225Z","shell.execute_reply.started":"2023-02-02T15:34:31.477629Z"},"trusted":true},"outputs":[],"source":["def read_csv(img,data,lbl,rot,id):\n","    rows = open('dataset4_csv/ID_'+str(id)+'.csv').read().strip().split('\\n')\n","    for row in rows:\n","        row = row.split(',')\n","        (x,y,label,rotation,pathimg) = row\n","        image =  load_img(pathimg, target_size=(256, 256))\n","        image = img_to_array(image)\n","        img.append(image)\n","        data.append([x,y])\n","        lbl.append(label)\n","        rot.append(rotation)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-02-02T15:34:39.576109Z","iopub.status.busy":"2023-02-02T15:34:39.575737Z","iopub.status.idle":"2023-02-02T15:39:59.747535Z","shell.execute_reply":"2023-02-02T15:39:59.746290Z","shell.execute_reply.started":"2023-02-02T15:34:39.576078Z"},"trusted":true},"outputs":[],"source":["if __name__ == '__main__':\n","    \n","    manager = multiprocessing.Manager()\n","    img = manager.list()\n","    data = manager.list()\n","    lbl = manager.list()\n","    rot = manager.list()\n","\n","    id = list(range(1,4))\n","\n","    partial_read_csv = functools.partial(read_csv, img, data, lbl, rot)\n","\n","    pool = multiprocessing.Pool()\n","    pool.map(partial_read_csv, id)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["pool.close()\n","pool.terminate()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["img = np.array(img,dtype='float32')\n","data = np.array(data,dtype='float32')\n","lbl = np.array(lbl)\n","rot = np.array(rot)\n","lb = LabelBinarizer()\n","lbl = lb.fit_transform(lbl)\n","rot = lb.fit_transform(rot)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-02-02T15:40:58.554965Z","iopub.status.busy":"2023-02-02T15:40:58.554576Z","iopub.status.idle":"2023-02-02T15:40:59.417025Z","shell.execute_reply":"2023-02-02T15:40:59.415951Z","shell.execute_reply.started":"2023-02-02T15:40:58.554932Z"},"trusted":true},"outputs":[],"source":["split = train_test_split(img, lbl, rot, data, test_size=0.1)\n","(trainImages, testImages) = split[:2]\n","(trainLabels, testLabels) = split[2:4]\n","(trainRotations, testRotations) = split[4:6]\n","(trainCoordinates, testCoordinates) = split[6:8]\n","split = train_test_split(trainImages, trainLabels, trainRotations, trainCoordinates, test_size=0.1)\n","(trainImages, valImages) = split[:2]\n","(trainLabels, valLabels) = split[2:4]\n","(trainRotations, valRotations) = split[4:6]\n","(trainCoordinates, valCoordinates) = split[6:8]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["MODEL CREATION"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-02-02T15:41:05.682248Z","iopub.status.busy":"2023-02-02T15:41:05.681869Z","iopub.status.idle":"2023-02-02T15:41:05.690261Z","shell.execute_reply":"2023-02-02T15:41:05.688719Z","shell.execute_reply.started":"2023-02-02T15:41:05.682214Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Rescaling, Dropout, BatchNormalization"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-02-02T15:41:08.168993Z","iopub.status.busy":"2023-02-02T15:41:08.168274Z","iopub.status.idle":"2023-02-02T15:41:08.198986Z","shell.execute_reply":"2023-02-02T15:41:08.198051Z","shell.execute_reply.started":"2023-02-02T15:41:08.168954Z"},"trusted":true},"outputs":[],"source":["#input layer\n","inputs = Input(shape=(256,256,3))\n","scaled_inputs = Rescaling(1/255)(inputs)\n","\n","#label branch\n","l = Conv2D(16, (3,3), 1, activation = 'relu', kernel_initializer='he_uniform', padding='same')(scaled_inputs)\n","l = BatchNormalization()(l)\n","l = MaxPooling2D()(l)\n","l = Dropout(0.2)(l)\n","l = Conv2D(32, (3,3), 1, activation = 'relu', kernel_initializer='he_uniform', padding='same')(l)\n","l = BatchNormalization()(l)\n","l = MaxPooling2D()(l)\n","l = Dropout(0.3)(l)\n","l = Conv2D(16, (3,3), 1, activation = 'relu', kernel_initializer='he_uniform', padding='same')(l)\n","l = BatchNormalization()(l)\n","l = MaxPooling2D()(l)\n","l = Dropout(0.4)(l)\n","l = Flatten()(l)\n","l = Dense(128, activation='relu', kernel_initializer='he_uniform')(l)\n","l = BatchNormalization()(l)\n","l = Dropout(0.5)(l)\n","l = Dense(3, activation = 'softmax', name='label')(l)\n","\n","#rot branch\n","r = Conv2D(16, (3,3), 1, activation = 'relu', kernel_initializer='he_uniform', padding='same')(scaled_inputs)\n","r = BatchNormalization()(r)\n","r = MaxPooling2D()(r)\n","r = Dropout(0.2)(r)\n","r = Conv2D(32, (3,3), 1, activation = 'relu', kernel_initializer='he_uniform', padding='same')(r)\n","r = BatchNormalization()(r)\n","r = MaxPooling2D()(r)\n","r = Dropout(0.3)(r)\n","r = Conv2D(16, (3,3), 1, activation = 'relu', kernel_initializer='he_uniform', padding='same')(r)\n","r = BatchNormalization()(r)\n","r = MaxPooling2D()(r)\n","r = Dropout(0.4)(r)\n","r = Flatten()(r)\n","r = Dense(128, activation='relu', kernel_initializer='he_uniform')(r)\n","r = BatchNormalization()(r)\n","r = Dropout(0.5)(r)\n","r = Dense(15, activation = 'softmax', name='rotation')(r)\n","\n","#ann branch\n","a = Conv2D(16, (3,3), 1, activation = 'relu')(scaled_inputs)\n","a = MaxPooling2D()(a)\n","a = Conv2D(32, (3,3), 1, activation = 'relu')(a)\n","a = MaxPooling2D()(a)\n","a = Conv2D(64, (3,3), 1, activation = 'relu')(a)\n","a = MaxPooling2D()(a)\n","a = Conv2D(128, (3,3), 1, activation = 'relu')(a)\n","a = MaxPooling2D()(a)\n","a = Flatten()(a)\n","a = Dense(32, activation = 'linear')(a)\n","a = Dense(32, activation = 'linear', kernel_regularizer='l2', bias_regularizer='l2')(a)\n","a = Dense(32, activation = 'linear', kernel_regularizer='l2', bias_regularizer='l2')(a)\n","a = Dense(32, activation = 'linear')(a)\n","a = Dense(2, activation = 'linear', name='coordinate')(a)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-02-02T15:41:18.926222Z","iopub.status.busy":"2023-02-02T15:41:18.925846Z","iopub.status.idle":"2023-02-02T15:41:18.938218Z","shell.execute_reply":"2023-02-02T15:41:18.937068Z","shell.execute_reply.started":"2023-02-02T15:41:18.926189Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-11 03:34:07.722647: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 4643094528 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","185/185 [==============================] - 308s 2s/step - loss: 2.1101 - label_loss: 0.5979 - rotation_loss: 1.2253 - coordinate_loss: 0.0011 - label_accuracy: 0.8018 - rotation_accuracy: 0.6567 - coordinate_accuracy: 0.8010 - val_loss: 3.9957 - val_label_loss: 1.3597 - val_rotation_loss: 2.5521 - val_coordinate_loss: 4.7699e-04 - val_label_accuracy: 0.3409 - val_rotation_accuracy: 0.1218 - val_coordinate_accuracy: 0.8554\n","Epoch 2/20\n","185/185 [==============================] - 267s 1s/step - loss: 0.7592 - label_loss: 0.2537 - rotation_loss: 0.4731 - coordinate_loss: 4.8091e-04 - label_accuracy: 0.9094 - rotation_accuracy: 0.8596 - coordinate_accuracy: 0.8606 - val_loss: 2.8639 - val_label_loss: 1.0214 - val_rotation_loss: 1.8355 - val_coordinate_loss: 4.1282e-04 - val_label_accuracy: 0.5312 - val_rotation_accuracy: 0.4338 - val_coordinate_accuracy: 0.8676\n","Epoch 3/20\n","185/185 [==============================] - 276s 1s/step - loss: 0.5064 - label_loss: 0.1737 - rotation_loss: 0.3301 - coordinate_loss: 4.2458e-04 - label_accuracy: 0.9392 - rotation_accuracy: 0.9075 - coordinate_accuracy: 0.8767 - val_loss: 1.1193 - val_label_loss: 0.3725 - val_rotation_loss: 0.7460 - val_coordinate_loss: 4.1641e-04 - val_label_accuracy: 0.8645 - val_rotation_accuracy: 0.8843 - val_coordinate_accuracy: 0.8615\n","Epoch 4/20\n","185/185 [==============================] - 316s 2s/step - loss: 0.3842 - label_loss: 0.1347 - rotation_loss: 0.2490 - coordinate_loss: 4.0681e-04 - label_accuracy: 0.9531 - rotation_accuracy: 0.9329 - coordinate_accuracy: 0.8799 - val_loss: 0.5043 - val_label_loss: 0.1811 - val_rotation_loss: 0.3228 - val_coordinate_loss: 3.5767e-04 - val_label_accuracy: 0.9437 - val_rotation_accuracy: 0.9330 - val_coordinate_accuracy: 0.8737\n","Epoch 5/20\n","185/185 [==============================] - 297s 2s/step - loss: 0.3017 - label_loss: 0.1043 - rotation_loss: 0.1969 - coordinate_loss: 3.8588e-04 - label_accuracy: 0.9673 - rotation_accuracy: 0.9448 - coordinate_accuracy: 0.8857 - val_loss: 0.3840 - val_label_loss: 0.1445 - val_rotation_loss: 0.2391 - val_coordinate_loss: 3.8506e-04 - val_label_accuracy: 0.9650 - val_rotation_accuracy: 0.9528 - val_coordinate_accuracy: 0.8889\n","Epoch 6/20\n","185/185 [==============================] - 329s 2s/step - loss: 0.2596 - label_loss: 0.1008 - rotation_loss: 0.1583 - coordinate_loss: 3.6950e-04 - label_accuracy: 0.9641 - rotation_accuracy: 0.9566 - coordinate_accuracy: 0.8908 - val_loss: 0.3863 - val_label_loss: 0.1446 - val_rotation_loss: 0.2413 - val_coordinate_loss: 3.7599e-04 - val_label_accuracy: 0.9604 - val_rotation_accuracy: 0.9406 - val_coordinate_accuracy: 0.8721\n","Epoch 7/20\n"," 62/185 [=========>....................] - ETA: 3:53 - loss: 0.2029 - label_loss: 0.0693 - rotation_loss: 0.1332 - coordinate_loss: 3.3098e-04 - label_accuracy: 0.9788 - rotation_accuracy: 0.9607 - coordinate_accuracy: 0.8992"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m#compile\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m{\n\u001b[1;32m      8\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mrotation\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mcoordinate\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m }, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     14\u001b[0m \ttrainImages, {\n\u001b[1;32m     15\u001b[0m \t\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m: trainLabels,\n\u001b[1;32m     16\u001b[0m \t\u001b[39m'\u001b[39;49m\u001b[39mrotation\u001b[39;49m\u001b[39m'\u001b[39;49m: trainRotations,\n\u001b[1;32m     17\u001b[0m \t\u001b[39m'\u001b[39;49m\u001b[39mcoordinate\u001b[39;49m\u001b[39m'\u001b[39;49m: trainCoordinates,\n\u001b[1;32m     18\u001b[0m },\n\u001b[1;32m     19\u001b[0m \tvalidation_data\u001b[39m=\u001b[39;49m (valImages, {\n\u001b[1;32m     20\u001b[0m \t\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m: valLabels,\n\u001b[1;32m     21\u001b[0m \t\u001b[39m'\u001b[39;49m\u001b[39mrotation\u001b[39;49m\u001b[39m'\u001b[39;49m: valRotations,\n\u001b[1;32m     22\u001b[0m \t\u001b[39m'\u001b[39;49m\u001b[39mcoordinate\u001b[39;49m\u001b[39m'\u001b[39;49m: valCoordinates,\n\u001b[1;32m     23\u001b[0m }),\n\u001b[1;32m     24\u001b[0m \tbatch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m \tepochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#model\n","model = Model(\n","\tinputs=inputs,\n","\toutputs=(l, r, a))\n","\n","#compile\n","model.compile(loss={\n","\t'label': 'categorical_crossentropy',\n","\t'rotation': 'categorical_crossentropy',\n","\t'coordinate': 'mse',\n","}, optimizer='adam', metrics=['accuracy'])\n","\n","hist = model.fit(\n","\ttrainImages, {\n","\t'label': trainLabels,\n","\t'rotation': trainRotations,\n","\t'coordinate': trainCoordinates,\n","},\n","\tvalidation_data= (valImages, {\n","\t'label': valLabels,\n","\t'rotation': valRotations,\n","\t'coordinate': valCoordinates,\n","}),\n","\tbatch_size=32,\n","\tepochs=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save('super2.h5')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["TESTING"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import cv2\n","from keras.models import load_model\n","from matplotlib import pyplot as plt\n","from keras.utils.vis_utils import plot_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = load_model('super1.h5', compile=False)\n","model.compile(loss={\n","\t'label': 'categorical_crossentropy',\n","\t'rotation': 'categorical_crossentropy',\n","\t'coordinate': 'mse',\n","}, optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_model(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image = cv2.imread('test_images/96trans50_-150.jpg')\n","image_show = np.array(image, dtype='float32')\n","height, width = image_show.shape[:2]\n","image_input = cv2.resize(image_show, (256,256))\n","plt.imshow(image_show)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = model.predict(np.expand_dims(image_input,0))\n","labels = ['ID_1', 'ID_2', 'ID_3']\n","rotations = [0,120,144,168,192,216,24,240,264,288,312,336,48,72,96]\n","label = y[0].argmax()\n","rotation = y[1].argmax()\n","co_x = y[2][0][0]\n","co_y = y[2][0][1]\n","cv2.circle(image_show, (int(np.around(co_x*width+width/2)),int(np.around(co_y*height+height/2))), 190, (255,255,255), thickness=2)\n","cv2.putText(image_show, str(labels[label]) + ' ' + str(rotations[rotation]) + ' degree', (100,100), cv2.FONT_HERSHEY_TRIPLEX, 4, (255,255,255), thickness=2)\n","plt.imshow(image_show)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"}}},"nbformat":4,"nbformat_minor":4}
